{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import time\n",
    "import urllib\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import csv\n",
    "from selenium.common.exceptions import *\n",
    "from urllib3.exceptions import *\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "df = pd.read_csv('crawl_target.csv',encoding=\"utf-8\")  \n",
    "year = 108\n",
    "str_year = str(year)\n",
    "num_of_pdf = []\n",
    "num_of_zip = []\n",
    "num_of_doc = []\n",
    "num_of_docx = []\n",
    "num_of_nosuch = []\n",
    "file_txt_all_list = []\n",
    "\n",
    "\n",
    "def webpath(co_id, str_year):\n",
    "    path = \"https://doc.twse.com.tw/server-java/t57sb01?step=1&colorchg=1&co_id=\"+ co_id +\"&year=\"+ str_year + \"&mtype=F&\"\n",
    "    return path\n",
    "\n",
    "def get_F04(path):\n",
    "    browser.get(path)\n",
    "#     headers = {\n",
    "#         'Connection': 'close',\n",
    "#         'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'\n",
    "#     }  \n",
    "    headers={'Connection':'close'}\n",
    "    session = requests.Session()\n",
    "    session.keep_alive = False\n",
    "    requests.adapters.DEFAULT_RETRIES = 5\n",
    "    res = requests.get(path, verify = False, headers = headers, timeout = 30)\n",
    "    selector = etree.HTML(res.text)\n",
    "    F04_repoert = selector.xpath(\"//*[contains(text(), 'F04')]\")\n",
    "    F04_repoert_name = F04_repoert[0].xpath('string(.)')\n",
    "    #print(\"年報表格檔名:\", F04_repoert[0].xpath('string(.)'))\n",
    "    return F04_repoert_name\n",
    "    \n",
    "\n",
    "def change_page():\n",
    "    WindowHandle = browser.current_window_handle\n",
    "    Title = browser.title\n",
    "    allHandles = browser.window_handles\n",
    "    routeWindowHandle = 0\n",
    "    routeTitle = 'None'\n",
    "    for handle in allHandles:\n",
    "        if handle != browser.current_window_handle:\n",
    "            browser.switch_to.window(handle)\n",
    "            routeWindowHandle = browser.current_window_handle\n",
    "            routeTitle = browser.title\n",
    "            break\n",
    "    \n",
    "def for_file_pdf(unclass_file_name, toneyeebanhao):\n",
    "    click_pdf_btn = browser.find_element_by_xpath(\"//*[contains(text(), 'F04')]\")\n",
    "    ActionChains(browser).click(click_pdf_btn).perform()   \n",
    "    change_page()\n",
    "    pdf_link = browser.find_element_by_xpath(\"//*[contains(text(), 'F04')]\")\n",
    "    if pdf_link == None:\n",
    "        print(\"pdf_link is none\")\n",
    "        global overdownload\n",
    "        overdownload == True\n",
    "        time.sleep(20)   \n",
    "    else:    \n",
    "        for link in browser.find_elements_by_tag_name(\"a\"):\n",
    "            filename = str(toneyeebanhao).zfill(8) + \".pdf\"\n",
    "            filepath = \"./save_crawl/\"\n",
    "            urllib.request.urlretrieve(link.get_attribute(\"href\"), filepath + filename)  \n",
    "            time.sleep(15)  \n",
    "\n",
    "    \n",
    "def for_other_file(co_id, unclass_file_name2, toneyeebanhao, file_classid):\n",
    "    download_url = \"https://doc.twse.com.tw/server-java/t57sb01?colorchg=1&step=9&kind=F&co_id=\"+ co_id +\"&filename=\"+ unclass_file_name\n",
    "    print(\"for_other_file:\",type(file_classid))\n",
    "    if file_classid  == 2 :\n",
    "        secondfilename =\".zip\"\n",
    "    elif file_classid  == 3:\n",
    "        secondfilename =\".doc\"\n",
    "    else:\n",
    "        secondfilename =\".docx\"\n",
    "    #print(\"for_other_file:\",secondfilename)\n",
    "    filename = str(toneyeebanhao).zfill(8) + secondfilename\n",
    "    filepath = \"./save_crawl/\"\n",
    "    urllib.request.urlretrieve(download_url, filepath + filename)\n",
    "    \n",
    "    \n",
    "def file_class(unclass_file_name):\n",
    "    if unclass_file_name.find(\".pdf\") != -1 :\n",
    "        file_classid = 1\n",
    "        num_of_pdf.append(1)\n",
    "    elif unclass_file_name.find(\".zip\") != -1 :\n",
    "        num_of_zip.append(2)\n",
    "        file_classid = 2      \n",
    "    elif unclass_file_name.find(\".doc\") != -1 :\n",
    "        num_of_doc.append(3)\n",
    "        file_classid = 3        \n",
    "    else:\n",
    "        num_of_docx.append(4)\n",
    "        file_classid = 4\n",
    "        \n",
    "    num = file_classid\n",
    "    unclass_file_name2 = unclass_file_name\n",
    "\n",
    "    if  file_classid == 2 or file_classid == 3 or file_classid == 4:\n",
    "        for_other_file(co_id, unclass_file_name2, toneyeebanhao, file_classid)\n",
    "    else:\n",
    "        for_file_pdf(unclass_file_name, toneyeebanhao)\n",
    "        \n",
    "    return file_classid, len(num_of_pdf), len(num_of_zip), len(num_of_doc), len(num_of_docx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "while i <= len(df): \n",
    "    global overdownload\n",
    "    overdownload = False\n",
    "    co_id = df['公司代號'][i]\n",
    "    if len(co_id) == 3:\n",
    "        co_id = co_id.zfill(3)\n",
    "    toneyeebanhao = df['營利事業統一編號'][i]\n",
    "    # chromedriver options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    dirpath = \"./save_crawl/\"\n",
    "    prefs = {\n",
    "                'profile.default_content_settings.popups': 0,\n",
    "                'download.default_directory': dirpath\n",
    "    } \n",
    "    options.add_experimental_option('prefs', prefs)\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "    browser.implicitly_wait(10)\n",
    "    browser.set_window_size(700,700)\n",
    "    current_link = webpath(co_id, str_year)\n",
    "    file_txt_list = []  \n",
    "    try:\n",
    "        unclass_file_name = get_F04(current_link)\n",
    "        if unclass_file_name ==\"\":\n",
    "            save_status = \"\"\n",
    "            save_status = \"沒有年報(找不到F04)\"\n",
    "            python_status = \"沒有年報\"\n",
    "        else:\n",
    "            save_status = \"\"\n",
    "            save_status = \"successful\"\n",
    "            python_status = \"Fine\"\n",
    "            file_class(unclass_file_name)\n",
    "            #print(file_class(unclass_file_name))\n",
    "\n",
    "    except MaxRetryError as e:\n",
    "            save_status = \"\"\n",
    "            save_status = \"successful\"\n",
    "            python_status = e\n",
    "            #print(\"MaxRetryError\",save_status)\n",
    "\n",
    "    except BaseException as e:\n",
    "            num_of_nosuch.append(co_id)\n",
    "            save_status = \"\"\n",
    "            save_status = \"FAIL\"\n",
    "            #print(\"save_status NoSuchElementException \",save_status)\n",
    "            python_status = e\n",
    "            browser.quit()\n",
    "\n",
    "    file_txt_list.append(time.asctime(time.localtime(time.time())))        \n",
    "    file_txt_list.append(co_id)\n",
    "    file_txt_list.append(toneyeebanhao)\n",
    "    file_txt_list.append(save_status)\n",
    "    file_txt_list.append(python_status)\n",
    "    file_txt_list.append(current_link)\n",
    "    file_txt_all_list.append(file_txt_list)\n",
    "    print(time.asctime(time.localtime(time.time())),\":\",i,\":\",save_status) \n",
    "\n",
    "    with open('./log/crawl_report.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(('時間','company_id', '統一編號','file status','python status', 'link'))\n",
    "        for it in file_txt_all_list:\n",
    "            writer.writerow((column for column in it))\n",
    "\n",
    "    if overdownload == False:\n",
    "        i+=1\n",
    "        time.sleep(20)\n",
    "    else:\n",
    "        time.sleep(600)\n",
    "    browser.quit() \n",
    "print(\"結束:\",time.asctime(time.localtime(time.time())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
